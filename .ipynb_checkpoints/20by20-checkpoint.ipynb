{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE474/574 - Programming Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Image Classification\n",
    "\n",
    "Additional library requirement: `Pillow`. See [here](https://anaconda.org/anaconda/pillow) for installation instructions.\n",
    "\n",
    "For this part, we will use `keras` with a `tensorflow` backend, instead of directly using `tensorflow`, as in Part 1. See [here](https://anaconda.org/conda-forge/keras) for installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(data,size):\n",
    "    '''\n",
    "    Resize images in a given data matrix (1 per row) to the specified size in the tuple - size.\n",
    "    '''\n",
    "    resized_data = np.empty((data.shape[0],size[0]*size[1]))\n",
    "    for i in range(data.shape[0]):\n",
    "        d = (np.array(Image.fromarray(data[i,:].reshape((28,28))).resize(size))).flatten()\n",
    "        resized_data[i,:] = d\n",
    "    return resized_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['apple', 'airplane', 'basketball', 'axe', 'banana', 'horse', 'arm', 'alarm clock', 'ant', 'bed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (20,20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5c677dd8534f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_ai_quick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlabel_test1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_ai_quick\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdata_train1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_train1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# convert labels to 0-1 hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4b4e7b5747d8>\u001b[0m in \u001b[0;36mresize_images\u001b[1;34m(data, size)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mresized_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mresized_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresized_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (20,20)"
     ]
    }
   ],
   "source": [
    "# Preparing the data set\n",
    "with open('AI_quick_draw.pickle', 'rb') as open_ai_quick:\n",
    "    data_train = pickle.load(open_ai_quick)\n",
    "    label_train1 = pickle.load(open_ai_quick)\n",
    "    data_test = pickle.load(open_ai_quick)\n",
    "    label_test1 = pickle.load(open_ai_quick)\n",
    "    data_train1 = resize_images(data_train,(20,20))\n",
    "n_classes = len(np.unique(label_train1))\n",
    "# convert labels to 0-1 hot encoding\n",
    "label_train = np.zeros((label_train1.shape[0], n_classes))\n",
    "a = np.arange(label_train1.shape[0], dtype=np.int64)\n",
    "b = np.array(label_train1, dtype=np.int64).reshape((label_train1.shape[0],))\n",
    "label_train[a, b] = 1\n",
    "\n",
    "label_test = np.zeros((label_test1.shape[0], n_classes))\n",
    "c = np.arange(label_test1.shape[0], dtype=np.int64)\n",
    "d = np.array(label_test1, dtype=np.int64).reshape((label_test1.shape[0],))\n",
    "label_test[c, d] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f5e38ea6d765>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_train1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize some images\n",
    "fig = plt.figure(figsize=[12,12])\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4,4,i+1)    \n",
    "    ind = np.random.randint(0,data_train1.shape[0])\n",
    "    plt.imshow(data_train1[ind,:].reshape((20,20)),cmap='Greys')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    t = plt.title(classes[int(label_train1[ind])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some macosx installations, conflicting copies of mpilib causes trouble with tensorflow.\n",
    "# use the following two lines to resolve that issue\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: This cell will take a significantly long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "100000/100000 [==============================] - 13s 129us/step - loss: 3.1788 - accuracy: 0.6085\n",
      "Epoch 2/500\n",
      "100000/100000 [==============================] - 11s 115us/step - loss: 1.4174 - accuracy: 0.6916\n",
      "Epoch 3/500\n",
      "100000/100000 [==============================] - 12s 118us/step - loss: 1.4077 - accuracy: 0.7058\n",
      "Epoch 4/500\n",
      "100000/100000 [==============================] - 11s 111us/step - loss: 1.3952 - accuracy: 0.7131\n",
      "Epoch 5/500\n",
      "100000/100000 [==============================] - 11s 111us/step - loss: 1.4013 - accuracy: 0.7200\n",
      "Epoch 6/500\n",
      "100000/100000 [==============================] - 11s 112us/step - loss: 1.3764 - accuracy: 0.7228\n",
      "Epoch 7/500\n",
      "100000/100000 [==============================] - 11s 115us/step - loss: 1.3933 - accuracy: 0.7259\n",
      "Epoch 8/500\n",
      "100000/100000 [==============================] - 12s 115us/step - loss: 1.3677 - accuracy: 0.7302\n",
      "Epoch 9/500\n",
      "100000/100000 [==============================] - 11s 114us/step - loss: 1.3701 - accuracy: 0.7326\n",
      "Epoch 10/500\n",
      "100000/100000 [==============================] - 11s 111us/step - loss: 1.3633 - accuracy: 0.7360\n",
      "Epoch 11/500\n",
      "100000/100000 [==============================] - 11s 112us/step - loss: 1.3577 - accuracy: 0.7365\n",
      "Epoch 12/500\n",
      "100000/100000 [==============================] - 11s 110us/step - loss: 1.3392 - accuracy: 0.7418\n",
      "Epoch 13/500\n",
      "100000/100000 [==============================] - 11s 113us/step - loss: 1.3267 - accuracy: 0.7446\n",
      "Epoch 14/500\n",
      "100000/100000 [==============================] - 11s 113us/step - loss: 1.3337 - accuracy: 0.7459\n",
      "Epoch 15/500\n",
      "100000/100000 [==============================] - 12s 116us/step - loss: 1.3288 - accuracy: 0.7459\n",
      "Epoch 16/500\n",
      "100000/100000 [==============================] - 11s 114us/step - loss: 1.3174 - accuracy: 0.7484\n",
      "Epoch 17/500\n",
      "100000/100000 [==============================] - 11s 112us/step - loss: 1.3074 - accuracy: 0.7510\n",
      "Epoch 18/500\n",
      "100000/100000 [==============================] - 11s 112us/step - loss: 1.3157 - accuracy: 0.7513\n",
      "Epoch 19/500\n",
      "100000/100000 [==============================] - 11s 113us/step - loss: 1.3036 - accuracy: 0.7522\n",
      "Epoch 20/500\n",
      "100000/100000 [==============================] - 12s 115us/step - loss: 1.2812 - accuracy: 0.7538\n",
      "Epoch 21/500\n",
      "100000/100000 [==============================] - 11s 115us/step - loss: 1.2659 - accuracy: 0.7558\n",
      "Epoch 22/500\n",
      "100000/100000 [==============================] - 11s 114us/step - loss: 1.2680 - accuracy: 0.7581\n",
      "Epoch 23/500\n",
      "100000/100000 [==============================] - 12s 115us/step - loss: 1.2671 - accuracy: 0.7567\n",
      "Epoch 24/500\n",
      "100000/100000 [==============================] - 11s 111us/step - loss: 1.2438 - accuracy: 0.7580\n",
      "Epoch 25/500\n",
      "100000/100000 [==============================] - 11s 112us/step - loss: 1.2463 - accuracy: 0.7621\n",
      "Epoch 26/500\n",
      "100000/100000 [==============================] - 11s 114us/step - loss: 1.2377 - accuracy: 0.7620\n",
      "Epoch 27/500\n",
      "100000/100000 [==============================] - 13s 126us/step - loss: 1.2376 - accuracy: 0.7652\n",
      "Epoch 28/500\n",
      "100000/100000 [==============================] - 12s 124us/step - loss: 1.2175 - accuracy: 0.7649\n",
      "Epoch 29/500\n",
      "100000/100000 [==============================] - 13s 133us/step - loss: 1.2087 - accuracy: 0.7660\n",
      "Epoch 30/500\n",
      "100000/100000 [==============================] - 12s 121us/step - loss: 1.1926 - accuracy: 0.7667\n",
      "Epoch 31/500\n",
      "100000/100000 [==============================] - 12s 125us/step - loss: 1.2034 - accuracy: 0.7663\n",
      "Epoch 32/500\n",
      "100000/100000 [==============================] - 12s 123us/step - loss: 1.1891 - accuracy: 0.7666\n",
      "Epoch 33/500\n",
      "100000/100000 [==============================] - 14s 135us/step - loss: 1.1794 - accuracy: 0.7669\n",
      "Epoch 34/500\n",
      "100000/100000 [==============================] - 14s 136us/step - loss: 1.1729 - accuracy: 0.7680\n",
      "Epoch 35/500\n",
      "100000/100000 [==============================] - 13s 125us/step - loss: 1.1611 - accuracy: 0.7685\n",
      "Epoch 36/500\n",
      "100000/100000 [==============================] - 13s 129us/step - loss: 1.1712 - accuracy: 0.7712\n",
      "Epoch 37/500\n",
      " 52128/100000 [==============>...............] - ETA: 6s - loss: 1.1320 - accuracy: 0.7788"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=data_train1.shape[1]))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "# you can add more Dense layers here\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data_train1, label_train, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to use with the drawing app (this will be released later)\n",
    "model.save('pa2-part2-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
